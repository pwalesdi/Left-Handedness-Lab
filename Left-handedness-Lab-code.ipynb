{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 1: Predicting Left-Handedness from Psychological Factors\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "We'll walk through a full data science problem in this lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Define The Problem.\n",
    "\n",
    "You're currently a data scientist working at a university. A professor of psychology is attempting to study the relationship between personalities and left-handedness. They have tasked you with gathering evidence so that they may publish.\n",
    "\n",
    "Specifically, the professor says \"I need to prove that left-handedness is caused by some personality trait. Go find that personality trait and the data to back it up.\"\n",
    "\n",
    "As a data scientist, you know that any real data science problem must be **specific** and **conclusively answerable**. For example:\n",
    "- Bad data science problem: \"What is the link between obesity and blood pressure?\"\n",
    "    - This is vague and is not conclusively answerable. That is, two people might look at the conclusion and one may say \"Sure, the problem has been answered!\" and the other may say \"The problem has not yet been answered.\"\n",
    "- Good data science problem: \"Does an association exist between obesity and blood pressure?\"\n",
    "    - This is more specific and is conclusively answerable. The problem specifically is asking for a \"Yes\" or \"No\" answer. Based on that, two independent people should both be able to say either \"Yes, the problem has been answered\" or \"No, the problem has not yet been answered.\"\n",
    "- Excellent data science problem: \"As obesity increases, how does blood pressure change?\"\n",
    "    - This is very specific and is conclusively answerable. The problem specifically seeks to understand the effect of one variable on the other.\n",
    "\n",
    "### 1. In the context of the left-handedness and personality example, what are three specific and conclusively answerable problems that you could answer using data science? \n",
    "\n",
    "> You might find it helpful to check out the codebook in the repo for some inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "1. Is lefthandedness more common in artistic people?\n",
    "2. Does an aggressive personality correlate more with left-handedness?\n",
    "3. Are people who are left-handed more analytical?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 2. Read in the file titled \"data.csv.\"\n",
    "> Hint: Despite being saved as a .csv file, you won't be able to simply `pd.read_csv()` this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import os\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q13</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q16</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q35</th>\n",
       "      <th>Q36</th>\n",
       "      <th>Q37</th>\n",
       "      <th>Q38</th>\n",
       "      <th>Q39</th>\n",
       "      <th>Q40</th>\n",
       "      <th>Q41</th>\n",
       "      <th>Q42</th>\n",
       "      <th>Q43</th>\n",
       "      <th>Q44</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>country</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>232</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>247</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6774</td>\n",
       "      <td>NL</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1072</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>226</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Q11  Q12  Q13  Q14  Q15  Q16  Q17  Q18  Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  Q29  Q30  Q31  Q32  Q33  Q34  Q35  Q36  Q37  Q38  Q39  Q40  Q41  Q42  Q43  Q44  introelapse  testelapse country  fromgoogle  engnat  age  education  gender  orientation  race  religion  hand\n",
       "0   4   1   5   1   5   1   5   1   4    1    1    1    5    5    5    1    5    1    5    1    5    1    1    1    5    5    5    1    5    1    1    1    1    5    5    1    1    1    5    5    5    1    5    1           91         232      US           2       1   22          3       1            1     3         2     3\n",
       "1   1   5   1   4   2   5   5   4   1    5    2    5    3    4    1    4    1    1    1    5    2    4    4    4    1    2    1    2    1    3    1    5    2    4    4    4    4    4    1    3    1    4    4    5           17         247      CA           2       1   14          1       2            2     6         1     1\n",
       "2   1   2   1   1   5   4   3   2   1    4    4    5    4    3    4    1    2    3    1    3    3    3    4    5    3    2    2    2    1    4    3    3    4    4    2    2    4    2    1    4    2    2    2    2           11        6774      NL           2       2   30          4       1            1     1         1     2\n",
       "3   1   4   1   5   1   4   5   4   3    5    1    3    2    3    1    5    2    2    5    5    2    3    2    2    1    4    1    1    1    3    4    1    3    5    5    1    3    4    1    2    1    1    1    3           14        1072      US           2       1   18          2       2            5     3         2     2\n",
       "4   5   1   5   1   5   1   5   1   3    1    1    1    5    5    5    1    5    1    5    2    5    1    5    1    5    5    5    1    5    1    5    1    5    5    5    1    1    1    5    5    5    1    5    1           10         226      US           2       1   22          3       1            1     3         2     3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lefthand = pd.read_csv('/Users/pwalesdi/4.01-lab-classification_model_comparison/data_1.txt', sep='\\t')\n",
    "lefthand.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Suppose that, instead of us giving you this data in a file, you were actually conducting a survey to gather this data yourself. From an ethics/privacy point of view, what are three things you might consider when attempting to gather this data?\n",
    "> When working with sensitive data like sexual orientation or gender identity, we need to consider how this data could be used if it fell into the wrong hands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 4. Conduct exploratory data analysis on this dataset.\n",
    "> If you haven't already, be sure to check out the codebook in the repo, as that will help in your EDA process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count\n",
       "hand       \n",
       "0        11\n",
       "1      3542\n",
       "2       452\n",
       "3       179"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lefthand.groupby('hand')['hand'].agg(['count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Q%s' % i for i in range(1,44)]\n",
    "lefthandcorr_1 = lefthand[features].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.030882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q26</th>\n",
       "      <td>0.018077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.017367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q25</th>\n",
       "      <td>0.015104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orientation</th>\n",
       "      <td>0.014769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5</th>\n",
       "      <td>0.014390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q21</th>\n",
       "      <td>0.013723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q31</th>\n",
       "      <td>0.011751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q17</th>\n",
       "      <td>0.006905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q38</th>\n",
       "      <td>0.004713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q33</th>\n",
       "      <td>0.004191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q11</th>\n",
       "      <td>0.002069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q29</th>\n",
       "      <td>0.001801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q35</th>\n",
       "      <td>0.001578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q7</th>\n",
       "      <td>-0.001571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q16</th>\n",
       "      <td>-0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>-0.002250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>-0.003281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q13</th>\n",
       "      <td>-0.003382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q10</th>\n",
       "      <td>-0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q12</th>\n",
       "      <td>-0.009483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q30</th>\n",
       "      <td>-0.010483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3</th>\n",
       "      <td>-0.011560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q24</th>\n",
       "      <td>-0.012669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testelapse</th>\n",
       "      <td>-0.014695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q28</th>\n",
       "      <td>-0.014995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q19</th>\n",
       "      <td>-0.015787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q32</th>\n",
       "      <td>-0.017179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>introelapse</th>\n",
       "      <td>-0.017314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q6</th>\n",
       "      <td>-0.017725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q37</th>\n",
       "      <td>-0.018194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion</th>\n",
       "      <td>-0.019956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q41</th>\n",
       "      <td>-0.021496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q36</th>\n",
       "      <td>-0.022079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q15</th>\n",
       "      <td>-0.023625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q44</th>\n",
       "      <td>-0.023858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q14</th>\n",
       "      <td>-0.023984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fromgoogle</th>\n",
       "      <td>-0.024406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q34</th>\n",
       "      <td>-0.024535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q18</th>\n",
       "      <td>-0.025164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9</th>\n",
       "      <td>-0.025695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>-0.027617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q27</th>\n",
       "      <td>-0.027993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q20</th>\n",
       "      <td>-0.028427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q39</th>\n",
       "      <td>-0.029842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q40</th>\n",
       "      <td>-0.030117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4</th>\n",
       "      <td>-0.034650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q42</th>\n",
       "      <td>-0.035204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q43</th>\n",
       "      <td>-0.037470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q23</th>\n",
       "      <td>-0.038913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q22</th>\n",
       "      <td>-0.043220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>-0.044746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q8</th>\n",
       "      <td>-0.049803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engnat</th>\n",
       "      <td>-0.050835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hand\n",
       "hand         1.000000\n",
       "age          0.030882\n",
       "Q26          0.018077\n",
       "education    0.017367\n",
       "Q25          0.015104\n",
       "orientation  0.014769\n",
       "Q5           0.014390\n",
       "Q21          0.013723\n",
       "Q31          0.011751\n",
       "Q17          0.006905\n",
       "Q38          0.004713\n",
       "Q33          0.004191\n",
       "Q11          0.002069\n",
       "Q29          0.001801\n",
       "Q35          0.001578\n",
       "Q7          -0.001571\n",
       "Q16         -0.001603\n",
       "Q1          -0.002250\n",
       "race        -0.003281\n",
       "Q13         -0.003382\n",
       "Q10         -0.003500\n",
       "Q12         -0.009483\n",
       "Q30         -0.010483\n",
       "Q3          -0.011560\n",
       "Q24         -0.012669\n",
       "testelapse  -0.014695\n",
       "Q28         -0.014995\n",
       "Q19         -0.015787\n",
       "Q32         -0.017179\n",
       "introelapse -0.017314\n",
       "Q6          -0.017725\n",
       "Q37         -0.018194\n",
       "religion    -0.019956\n",
       "Q41         -0.021496\n",
       "Q36         -0.022079\n",
       "Q15         -0.023625\n",
       "Q44         -0.023858\n",
       "Q14         -0.023984\n",
       "fromgoogle  -0.024406\n",
       "Q34         -0.024535\n",
       "Q18         -0.025164\n",
       "Q9          -0.025695\n",
       "Q2          -0.027617\n",
       "Q27         -0.027993\n",
       "Q20         -0.028427\n",
       "Q39         -0.029842\n",
       "Q40         -0.030117\n",
       "Q4          -0.034650\n",
       "Q42         -0.035204\n",
       "Q43         -0.037470\n",
       "Q23         -0.038913\n",
       "Q22         -0.043220\n",
       "gender      -0.044746\n",
       "Q8          -0.049803\n",
       "engnat      -0.050835"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lefthand.corr()[['hand']].sort_values('hand', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (40, 35))\n",
    "# mask = np.zeros_like(lefthandcorr_1)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "# sns.set(font_scale = 2)\n",
    "# ax = sns.heatmap(lefthandcorr_1, mask=mask, annot=True, cmap='RdYlBu', vmax=1, vmin=-1, \n",
    "# square=False, linewidths=1.5,  cbar_kws={\"shrink\": 1.0}, xticklabels='auto')\n",
    "# plt.xticks(rotation=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 5. Suppose I wanted to use Q1 - Q44 to predict whether or not the person is left-handed. Would this be a classification or regression problem? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed based on their responses to Q1 - Q44. Before doing that, however, you remember that it is often a good idea to standardize your variables. In general, why would we standardize our variables? Give an example of when we would standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Give an example of when we might not standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Based on your answers to 6 and 7, do you think we should standardize our predictor variables in this case? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed. What munging/cleaning do we need to do to our $y$ variable in order to explicitly answer this question? Do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(lefthand, hue='hand');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lefthand.groupby('hand')['hand'].agg(['count'])\n",
    "lefthand = lefthand.loc[(lefthand['hand'] == 1) | (lefthand['hand'] == 2)]\n",
    "\n",
    "lefthand.loc[(lefthand['hand'] == 1), 'hand'] = 0\n",
    "\n",
    "lefthand.loc[(lefthand['hand'] == 2), 'hand'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count\n",
       "hand       \n",
       "0      3542\n",
       "1       452"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lefthand.groupby('hand')['hand'].agg(['count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hand</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.030882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q26</th>\n",
       "      <td>0.018077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0.017367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q25</th>\n",
       "      <td>0.015104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orientation</th>\n",
       "      <td>0.014769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5</th>\n",
       "      <td>0.014390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q21</th>\n",
       "      <td>0.013723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q31</th>\n",
       "      <td>0.011751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q17</th>\n",
       "      <td>0.006905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q38</th>\n",
       "      <td>0.004713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q33</th>\n",
       "      <td>0.004191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q11</th>\n",
       "      <td>0.002069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q29</th>\n",
       "      <td>0.001801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q35</th>\n",
       "      <td>0.001578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q7</th>\n",
       "      <td>-0.001571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q16</th>\n",
       "      <td>-0.001603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>-0.002250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>-0.003281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q13</th>\n",
       "      <td>-0.003382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q10</th>\n",
       "      <td>-0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q12</th>\n",
       "      <td>-0.009483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q30</th>\n",
       "      <td>-0.010483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3</th>\n",
       "      <td>-0.011560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q24</th>\n",
       "      <td>-0.012669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testelapse</th>\n",
       "      <td>-0.014695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q28</th>\n",
       "      <td>-0.014995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q19</th>\n",
       "      <td>-0.015787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q32</th>\n",
       "      <td>-0.017179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>introelapse</th>\n",
       "      <td>-0.017314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q6</th>\n",
       "      <td>-0.017725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q37</th>\n",
       "      <td>-0.018194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>religion</th>\n",
       "      <td>-0.019956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q41</th>\n",
       "      <td>-0.021496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q36</th>\n",
       "      <td>-0.022079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q15</th>\n",
       "      <td>-0.023625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q44</th>\n",
       "      <td>-0.023858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q14</th>\n",
       "      <td>-0.023984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fromgoogle</th>\n",
       "      <td>-0.024406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q34</th>\n",
       "      <td>-0.024535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q18</th>\n",
       "      <td>-0.025164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q9</th>\n",
       "      <td>-0.025695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>-0.027617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q27</th>\n",
       "      <td>-0.027993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q20</th>\n",
       "      <td>-0.028427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q39</th>\n",
       "      <td>-0.029842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q40</th>\n",
       "      <td>-0.030117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4</th>\n",
       "      <td>-0.034650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q42</th>\n",
       "      <td>-0.035204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q43</th>\n",
       "      <td>-0.037470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q23</th>\n",
       "      <td>-0.038913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q22</th>\n",
       "      <td>-0.043220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>-0.044746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q8</th>\n",
       "      <td>-0.049803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engnat</th>\n",
       "      <td>-0.050835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hand\n",
       "hand         1.000000\n",
       "age          0.030882\n",
       "Q26          0.018077\n",
       "education    0.017367\n",
       "Q25          0.015104\n",
       "orientation  0.014769\n",
       "Q5           0.014390\n",
       "Q21          0.013723\n",
       "Q31          0.011751\n",
       "Q17          0.006905\n",
       "Q38          0.004713\n",
       "Q33          0.004191\n",
       "Q11          0.002069\n",
       "Q29          0.001801\n",
       "Q35          0.001578\n",
       "Q7          -0.001571\n",
       "Q16         -0.001603\n",
       "Q1          -0.002250\n",
       "race        -0.003281\n",
       "Q13         -0.003382\n",
       "Q10         -0.003500\n",
       "Q12         -0.009483\n",
       "Q30         -0.010483\n",
       "Q3          -0.011560\n",
       "Q24         -0.012669\n",
       "testelapse  -0.014695\n",
       "Q28         -0.014995\n",
       "Q19         -0.015787\n",
       "Q32         -0.017179\n",
       "introelapse -0.017314\n",
       "Q6          -0.017725\n",
       "Q37         -0.018194\n",
       "religion    -0.019956\n",
       "Q41         -0.021496\n",
       "Q36         -0.022079\n",
       "Q15         -0.023625\n",
       "Q44         -0.023858\n",
       "Q14         -0.023984\n",
       "fromgoogle  -0.024406\n",
       "Q34         -0.024535\n",
       "Q18         -0.025164\n",
       "Q9          -0.025695\n",
       "Q2          -0.027617\n",
       "Q27         -0.027993\n",
       "Q20         -0.028427\n",
       "Q39         -0.029842\n",
       "Q40         -0.030117\n",
       "Q4          -0.034650\n",
       "Q42         -0.035204\n",
       "Q43         -0.037470\n",
       "Q23         -0.038913\n",
       "Q22         -0.043220\n",
       "gender      -0.044746\n",
       "Q8          -0.049803\n",
       "engnat      -0.050835"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. The professor for whom you work suggests that you set $k = 4$. In this specific case, why might this be a bad idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Let's *(finally)* use $k$-nearest neighbors to predict whether or not a person is left-handed!\n",
    "\n",
    "> Be sure to create a train/test split with your data!\n",
    "\n",
    "> Create four separate models, one with $k = 3$, one with $k = 5$, one with $k = 15$, and one with $k = 25$.\n",
    "\n",
    "\n",
    "> Instantiate and fit your models.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       0\n",
       "2       1\n",
       "3       1\n",
       "5       0\n",
       "6       0\n",
       "7       0\n",
       "8       0\n",
       "9       1\n",
       "10      0\n",
       "11      0\n",
       "12      0\n",
       "13      0\n",
       "14      0\n",
       "15      0\n",
       "16      0\n",
       "17      0\n",
       "18      0\n",
       "19      0\n",
       "20      1\n",
       "21      0\n",
       "22      0\n",
       "23      0\n",
       "24      0\n",
       "25      0\n",
       "26      0\n",
       "27      0\n",
       "29      1\n",
       "30      0\n",
       "31      0\n",
       "32      0\n",
       "33      0\n",
       "34      1\n",
       "35      0\n",
       "36      0\n",
       "38      0\n",
       "39      0\n",
       "40      0\n",
       "41      0\n",
       "42      0\n",
       "43      0\n",
       "44      0\n",
       "45      0\n",
       "46      0\n",
       "47      0\n",
       "48      0\n",
       "49      0\n",
       "50      0\n",
       "51      1\n",
       "52      0\n",
       "53      0\n",
       "54      0\n",
       "55      1\n",
       "56      0\n",
       "57      0\n",
       "58      0\n",
       "59      0\n",
       "60      0\n",
       "61      1\n",
       "62      0\n",
       "63      0\n",
       "64      0\n",
       "65      0\n",
       "67      0\n",
       "68      1\n",
       "69      0\n",
       "70      1\n",
       "71      1\n",
       "73      0\n",
       "74      0\n",
       "75      0\n",
       "77      1\n",
       "78      0\n",
       "79      0\n",
       "80      1\n",
       "81      0\n",
       "82      0\n",
       "83      1\n",
       "84      0\n",
       "85      1\n",
       "86      1\n",
       "87      0\n",
       "88      0\n",
       "89      0\n",
       "90      0\n",
       "91      0\n",
       "92      1\n",
       "93      0\n",
       "94      0\n",
       "95      1\n",
       "96      0\n",
       "97      0\n",
       "98      0\n",
       "99      0\n",
       "100     0\n",
       "101     0\n",
       "102     0\n",
       "103     0\n",
       "104     0\n",
       "105     0\n",
       "106     1\n",
       "107     0\n",
       "108     0\n",
       "109     0\n",
       "110     0\n",
       "111     0\n",
       "112     0\n",
       "113     0\n",
       "115     0\n",
       "116     0\n",
       "117     1\n",
       "118     1\n",
       "119     0\n",
       "120     0\n",
       "121     0\n",
       "122     0\n",
       "123     0\n",
       "124     0\n",
       "125     0\n",
       "126     0\n",
       "127     0\n",
       "128     0\n",
       "129     0\n",
       "130     0\n",
       "131     0\n",
       "132     0\n",
       "133     0\n",
       "134     0\n",
       "136     0\n",
       "137     0\n",
       "138     0\n",
       "139     0\n",
       "140     0\n",
       "141     0\n",
       "142     0\n",
       "143     0\n",
       "144     0\n",
       "145     0\n",
       "146     0\n",
       "147     0\n",
       "148     0\n",
       "149     0\n",
       "150     0\n",
       "151     0\n",
       "152     0\n",
       "153     1\n",
       "154     0\n",
       "155     0\n",
       "156     0\n",
       "157     0\n",
       "158     0\n",
       "159     0\n",
       "160     0\n",
       "161     0\n",
       "162     0\n",
       "163     0\n",
       "164     0\n",
       "165     0\n",
       "166     0\n",
       "167     0\n",
       "168     1\n",
       "169     0\n",
       "170     1\n",
       "171     0\n",
       "172     1\n",
       "173     0\n",
       "175     0\n",
       "176     0\n",
       "177     0\n",
       "178     0\n",
       "179     0\n",
       "180     0\n",
       "181     0\n",
       "182     0\n",
       "183     0\n",
       "184     0\n",
       "185     0\n",
       "186     0\n",
       "187     1\n",
       "188     1\n",
       "189     0\n",
       "190     0\n",
       "191     1\n",
       "192     0\n",
       "193     0\n",
       "194     0\n",
       "195     0\n",
       "196     0\n",
       "197     0\n",
       "198     0\n",
       "199     0\n",
       "200     1\n",
       "201     0\n",
       "202     0\n",
       "203     0\n",
       "204     0\n",
       "205     0\n",
       "206     0\n",
       "207     1\n",
       "208     1\n",
       "209     0\n",
       "210     0\n",
       "211     0\n",
       "212     0\n",
       "213     0\n",
       "214     0\n",
       "215     0\n",
       "216     0\n",
       "217     0\n",
       "219     0\n",
       "222     0\n",
       "223     0\n",
       "224     0\n",
       "225     0\n",
       "226     0\n",
       "227     0\n",
       "228     0\n",
       "229     0\n",
       "230     0\n",
       "231     0\n",
       "232     0\n",
       "234     0\n",
       "235     0\n",
       "236     0\n",
       "237     0\n",
       "238     0\n",
       "239     0\n",
       "240     0\n",
       "241     0\n",
       "242     0\n",
       "243     0\n",
       "244     0\n",
       "245     0\n",
       "246     0\n",
       "247     0\n",
       "248     0\n",
       "249     0\n",
       "250     0\n",
       "251     0\n",
       "252     0\n",
       "253     0\n",
       "254     0\n",
       "255     0\n",
       "257     0\n",
       "258     0\n",
       "259     0\n",
       "260     0\n",
       "261     0\n",
       "262     1\n",
       "263     0\n",
       "264     0\n",
       "       ..\n",
       "3928    0\n",
       "3929    1\n",
       "3930    0\n",
       "3931    0\n",
       "3932    0\n",
       "3933    0\n",
       "3934    0\n",
       "3935    0\n",
       "3936    0\n",
       "3937    0\n",
       "3938    0\n",
       "3939    0\n",
       "3940    0\n",
       "3941    0\n",
       "3942    0\n",
       "3943    0\n",
       "3944    0\n",
       "3945    0\n",
       "3946    0\n",
       "3947    0\n",
       "3948    0\n",
       "3949    0\n",
       "3950    0\n",
       "3951    1\n",
       "3952    0\n",
       "3953    0\n",
       "3954    0\n",
       "3955    0\n",
       "3956    0\n",
       "3957    0\n",
       "3958    0\n",
       "3959    0\n",
       "3960    0\n",
       "3961    0\n",
       "3962    0\n",
       "3963    0\n",
       "3964    0\n",
       "3965    0\n",
       "3966    0\n",
       "3967    0\n",
       "3968    0\n",
       "3969    0\n",
       "3970    0\n",
       "3971    0\n",
       "3972    0\n",
       "3973    0\n",
       "3974    0\n",
       "3975    0\n",
       "3976    0\n",
       "3977    0\n",
       "3978    0\n",
       "3979    0\n",
       "3980    1\n",
       "3981    0\n",
       "3982    0\n",
       "3983    0\n",
       "3984    0\n",
       "3985    0\n",
       "3986    0\n",
       "3987    0\n",
       "3988    0\n",
       "3989    0\n",
       "3990    0\n",
       "3991    0\n",
       "3992    0\n",
       "3993    0\n",
       "3994    0\n",
       "3995    0\n",
       "3996    0\n",
       "3997    0\n",
       "3999    1\n",
       "4001    0\n",
       "4002    0\n",
       "4003    1\n",
       "4004    0\n",
       "4005    0\n",
       "4006    0\n",
       "4007    1\n",
       "4008    0\n",
       "4009    0\n",
       "4010    0\n",
       "4011    0\n",
       "4012    0\n",
       "4013    0\n",
       "4014    0\n",
       "4016    0\n",
       "4017    0\n",
       "4018    0\n",
       "4019    1\n",
       "4020    0\n",
       "4021    0\n",
       "4022    0\n",
       "4023    1\n",
       "4024    1\n",
       "4025    0\n",
       "4026    0\n",
       "4027    0\n",
       "4028    0\n",
       "4029    1\n",
       "4030    0\n",
       "4031    0\n",
       "4032    0\n",
       "4033    0\n",
       "4034    0\n",
       "4035    0\n",
       "4036    0\n",
       "4037    0\n",
       "4038    1\n",
       "4039    0\n",
       "4040    0\n",
       "4041    0\n",
       "4042    1\n",
       "4043    0\n",
       "4044    0\n",
       "4045    0\n",
       "4046    0\n",
       "4047    1\n",
       "4048    0\n",
       "4049    0\n",
       "4050    0\n",
       "4051    0\n",
       "4052    0\n",
       "4053    0\n",
       "4054    0\n",
       "4055    0\n",
       "4056    0\n",
       "4057    0\n",
       "4058    0\n",
       "4059    0\n",
       "4060    0\n",
       "4061    0\n",
       "4062    1\n",
       "4063    0\n",
       "4064    0\n",
       "4065    0\n",
       "4066    0\n",
       "4067    0\n",
       "4068    0\n",
       "4069    0\n",
       "4070    0\n",
       "4071    0\n",
       "4072    1\n",
       "4073    0\n",
       "4074    0\n",
       "4075    0\n",
       "4076    0\n",
       "4077    0\n",
       "4078    0\n",
       "4079    0\n",
       "4080    0\n",
       "4081    1\n",
       "4082    0\n",
       "4083    0\n",
       "4084    0\n",
       "4086    0\n",
       "4087    0\n",
       "4088    0\n",
       "4089    0\n",
       "4090    0\n",
       "4091    0\n",
       "4092    1\n",
       "4093    1\n",
       "4094    0\n",
       "4095    0\n",
       "4096    0\n",
       "4097    0\n",
       "4098    0\n",
       "4099    0\n",
       "4100    0\n",
       "4101    0\n",
       "4102    0\n",
       "4103    0\n",
       "4104    0\n",
       "4105    0\n",
       "4106    0\n",
       "4107    0\n",
       "4108    0\n",
       "4109    0\n",
       "4110    0\n",
       "4111    0\n",
       "4112    0\n",
       "4113    0\n",
       "4114    0\n",
       "4115    0\n",
       "4116    0\n",
       "4117    0\n",
       "4118    0\n",
       "4119    0\n",
       "4120    0\n",
       "4121    0\n",
       "4122    0\n",
       "4123    0\n",
       "4124    0\n",
       "4125    0\n",
       "4126    0\n",
       "4127    0\n",
       "4128    0\n",
       "4129    0\n",
       "4130    0\n",
       "4131    0\n",
       "4133    0\n",
       "4134    0\n",
       "4135    0\n",
       "4136    0\n",
       "4137    0\n",
       "4138    0\n",
       "4139    0\n",
       "4140    0\n",
       "4141    0\n",
       "4142    0\n",
       "4143    0\n",
       "4144    0\n",
       "4145    0\n",
       "4146    0\n",
       "4147    0\n",
       "4148    0\n",
       "4150    0\n",
       "4151    0\n",
       "4152    0\n",
       "4153    0\n",
       "4154    0\n",
       "4155    0\n",
       "4156    0\n",
       "4157    0\n",
       "4158    0\n",
       "4159    0\n",
       "4160    0\n",
       "4161    0\n",
       "4162    0\n",
       "4163    0\n",
       "4164    0\n",
       "4165    0\n",
       "4166    0\n",
       "4167    0\n",
       "4168    0\n",
       "4169    0\n",
       "4170    1\n",
       "4171    0\n",
       "4172    0\n",
       "4173    0\n",
       "4174    0\n",
       "4175    0\n",
       "4176    0\n",
       "4177    0\n",
       "4178    0\n",
       "4179    0\n",
       "4180    0\n",
       "4181    0\n",
       "4182    0\n",
       "4183    0\n",
       "Name: hand, Length: 3994, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lefthand['hand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.854754269006501\n",
      "0.8741215850274425\n",
      "0.8871461056424401\n",
      "0.8871461056424401\n"
     ]
    }
   ],
   "source": [
    "X=lefthand[features]\n",
    "y=lefthand['hand']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn15 = KNeighborsClassifier(n_neighbors=15)\n",
    "knn25 = KNeighborsClassifier(n_neighbors=25)\n",
    "print(cross_val_score(knn3, X_train, y_train, cv=5).mean())\n",
    "print(cross_val_score(knn5, X_train, y_train, cv=5).mean())\n",
    "print(cross_val_score(knn15, X_train, y_train, cv=5).mean())\n",
    "print(cross_val_score(knn25, X_train, y_train, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn 3: 0.8958263772954925\n",
      "0.889482470784641\n",
      "0.8871452420701169\n",
      "0.8871452420701169\n",
      "\n",
      "\n",
      "0.8558558558558559\n",
      "0.8718718718718719\n",
      "0.8858858858858859\n",
      "0.8858858858858859\n"
     ]
    }
   ],
   "source": [
    "knn3.fit(X_train, y_train)\n",
    "knn5.fit(X_train, y_train)\n",
    "knn15.fit(X_train, y_train)\n",
    "knn25.fit(X_train, y_train)\n",
    "\n",
    "print(f'Knn 3: {knn3.score(X_train, y_train)}')\n",
    "print(knn5.score(X_train, y_train))\n",
    "print(knn15.score(X_train, y_train))\n",
    "print(knn25.score(X_train, y_train))\n",
    "print('\\n')\n",
    "print(knn3.score(X_test, y_test))\n",
    "print(knn5.score(X_test, y_test))\n",
    "print(knn15.score(X_test, y_test))\n",
    "print(knn25.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2995, 43)\n",
      "(999, 43)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          count\n",
      "1              \n",
      "0.000000    672\n",
      "0.333333    288\n",
      "0.666667     39\n",
      "          count\n",
      "0              \n",
      "0.333333     39\n",
      "0.666667    288\n",
      "1.000000    672\n",
      "     count\n",
      "1         \n",
      "0.0    506\n",
      "0.2    365\n",
      "0.4    113\n",
      "0.6     14\n",
      "0.8      1\n",
      "     count\n",
      "0         \n",
      "0.2      1\n",
      "0.4     14\n",
      "0.6    113\n",
      "0.8    365\n",
      "1.0    506\n",
      "          count\n",
      "1              \n",
      "0.000000    129\n",
      "0.066667    300\n",
      "0.133333    299\n",
      "0.200000    169\n",
      "0.266667     73\n",
      "0.333333     26\n",
      "0.400000      3\n",
      "          count\n",
      "0              \n",
      "0.600000      3\n",
      "0.666667     26\n",
      "0.733333     73\n",
      "0.800000    169\n",
      "0.866667    299\n",
      "0.933333    300\n",
      "1.000000    129\n",
      "      count\n",
      "1          \n",
      "0.00     29\n",
      "0.04    125\n",
      "0.08    248\n",
      "0.12    232\n",
      "0.16    200\n",
      "0.20    100\n",
      "0.24     47\n",
      "0.28     14\n",
      "0.32      3\n",
      "0.36      1\n",
      "      count\n",
      "0          \n",
      "0.64      1\n",
      "0.68      3\n",
      "0.72     14\n",
      "0.76     47\n",
      "0.80    100\n",
      "0.84    200\n",
      "0.88    232\n",
      "0.92    248\n",
      "0.96    125\n",
      "1.00     29\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(knn3.predict_proba(X_test)).groupby(1)[1].agg(['count']))\n",
    "print(pd.DataFrame(knn3.predict_proba(X_test)).groupby(0)[0].agg(['count']))\n",
    "\n",
    "print(pd.DataFrame(knn5.predict_proba(X_test)).groupby(1)[1].agg(['count']))\n",
    "print(pd.DataFrame(knn5.predict_proba(X_test)).groupby(0)[0].agg(['count']))\n",
    "\n",
    "print(pd.DataFrame(knn15.predict_proba(X_test)).groupby(1)[1].agg(['count']))\n",
    "print(pd.DataFrame(knn15.predict_proba(X_test)).groupby(0)[0].agg(['count']))\n",
    "\n",
    "print(pd.DataFrame(knn25.predict_proba(X_test)).groupby(1)[1].agg(['count']))\n",
    "print(pd.DataFrame(knn25.predict_proba(X_test)).groupby(0)[0].agg(['count']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being good data scientists, we know that we might not run just one type of model. We might run many different models and see which is best.\n",
    "\n",
    "### 12. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, let's check the [documentation for logistic regression in sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Is there default regularization? If so, what is it? If not, how do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, should we standardize our features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Let's use logistic regression to predict whether or not the person is left-handed.\n",
    "\n",
    "\n",
    "> Be sure to use the same train/test split with your data as with your $k$-NN model above!\n",
    "\n",
    "> Create four separate models, one with LASSO and $\\alpha = 1$, one with LASSO and $\\alpha = 10$, one with Ridge and $\\alpha = 1$, and one with Ridge and $\\alpha = 10$. *(Hint: Be careful with how you specify $\\alpha$ in your model!)*\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [-0.73645188]\n",
      "\n",
      "Coefficient: [[-0.00742977 -0.04699472 -0.02072117 -0.08772433  0.06190146  0.01852482\n",
      "   0.026479   -0.1512281  -0.07371314  0.09729255  0.02355302 -0.02609583\n",
      "  -0.02224154  0.0202397   0.00157273  0.02621971  0.02692335  0.02326376\n",
      "  -0.04747419 -0.04799327 -0.05686107 -0.11065629 -0.03460374  0.0130884\n",
      "   0.0366283   0.10629215  0.02588428  0.01945747  0.06786362  0.05647171\n",
      "   0.03730987 -0.04060414 -0.02522169 -0.02156501  0.02603763  0.00324536\n",
      "  -0.03901551  0.08766737 -0.07721802 -0.06194837 -0.07073831 -0.0424616\n",
      "  -0.11139356]]\n",
      "\n",
      "Exponentiated Coefficient: [[0.99259777 0.95409243 0.97949204 0.91601336 1.06385751 1.01869747\n",
      "  1.02683268 0.85965159 0.92893813 1.10218278 1.02383258 0.97424172\n",
      "  0.97800398 1.02044591 1.00157396 1.02656647 1.02728906 1.02353647\n",
      "  0.95363509 0.9531402  0.94472531 0.8952464  0.96598812 1.01317442\n",
      "  1.03730739 1.11214674 1.02622219 1.019648   1.07021935 1.05809668\n",
      "  1.03801462 0.96020916 0.97509372 0.97866585 1.02637957 1.00325063\n",
      "  0.96173579 1.09162496 0.92568802 0.93993141 0.93170568 0.95842727\n",
      "  0.89458661]]\n"
     ]
    }
   ],
   "source": [
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, y_train)\n",
    "print(f'Intercept: {LogReg.intercept_}')\n",
    "print('')\n",
    "print(f'Coefficient: {LogReg.coef_}')\n",
    "print('')\n",
    "print(f'Exponentiated Coefficient: {np.exp(LogReg.coef_)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg predicted values: [0 0 0 0 0]\n",
      "Logreg predicted probabilities: [[0.85846189 0.14153811]\n",
      " [0.90611194 0.09388806]\n",
      " [0.92950981 0.07049019]\n",
      " [0.84417505 0.15582495]\n",
      " [0.88558955 0.11441045]]\n"
     ]
    }
   ],
   "source": [
    "print(f'Logreg predicted values: {LogReg.predict(X_train.head())}')\n",
    "print(f'Logreg predicted probabilities: {LogReg.predict_proba(X_train.head())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[885,   0],\n",
       "       [114,   0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "preds = LogReg.predict(X_test)\n",
    "confusion_matrix(y_test, # True values.\n",
    "                 preds)  # Predicted values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 1.0\n"
     ]
    }
   ],
   "source": [
    "spec = tn / (tn + fp)\n",
    "\n",
    "print(f'Specificity: {round(spec,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.0\n"
     ]
    }
   ],
   "source": [
    "sens = tp / (tp + fn)\n",
    "\n",
    "print(f'Sensitivity: {round(sens,4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8858858858858859\n",
      "0.8858858858858859\n",
      "0.8858858858858859\n",
      "0.8858858858858859\n",
      "[[-0.00569758 -0.04638346 -0.01853951 -0.08578679  0.0611854   0.01498284\n",
      "   0.02313173 -0.15160932 -0.07244508  0.09335324  0.02060853 -0.02588533\n",
      "  -0.02263529  0.01699182  0.          0.02431994  0.02555358  0.02070302\n",
      "  -0.04698055 -0.04648088 -0.05736181 -0.10935238 -0.03332322  0.00988677\n",
      "   0.03288868  0.10455288  0.00971169  0.01825499  0.06540237  0.0542085\n",
      "   0.03288798 -0.03912474 -0.02451964 -0.02074129  0.02332908  0.\n",
      "  -0.03805837  0.08445194 -0.07508504 -0.05909796 -0.06913453 -0.04056245\n",
      "  -0.09535763]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LogRegL1 = LogisticRegression(penalty='l1', C=1, solver='liblinear')\n",
    "LogRegL2 = LogisticRegression(penalty='l2', C=1, solver='liblinear')\n",
    "LogRegL1_10 = LogisticRegression(penalty='l1', C=10, solver='liblinear')\n",
    "LogRegL2_10 = LogisticRegression(penalty='l2', C=10, solver='liblinear')\n",
    "\n",
    "LogRegL1.fit(X_train, y_train)\n",
    "LogRegL2.fit(X_train, y_train)\n",
    "LogRegL1_10.fit(X_train, y_train)\n",
    "LogRegL2_10.fit(X_train, y_train)\n",
    "\n",
    "print(LogRegL1.score(X_test, y_test))\n",
    "print(LogRegL2.score(X_test, y_test))\n",
    "print(LogRegL1_10.score(X_test, y_test))\n",
    "print(LogRegL2_10.score(X_test, y_test))\n",
    "\n",
    "print(LogRegL1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8871465960261951\n",
      "0.8871465960261951\n",
      "0.8871465960261951\n",
      "0.8871465960261951\n"
     ]
    }
   ],
   "source": [
    "cvs_L_1 = cross_val_score(LogRegL1, X_train, y_train, cv=7).mean()\n",
    "cvs_L_10 = cross_val_score(LogRegL1_10, X_train, y_train, cv=7).mean()\n",
    "cvs_r_1 = cross_val_score(LogRegL2, X_train, y_train, cv=7).mean()\n",
    "cvs_r_10 = cross_val_score(LogRegL2_10, X_train, y_train, cv=7).mean()\n",
    "print(cvs_L_1)\n",
    "print(cvs_L_10)\n",
    "print(cvs_r_1)\n",
    "print(cvs_r_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Evaluate the model(s).\n",
    "\n",
    "### 15. Before calculating any score on your data, take a step back. Think about your $X$ variable and your $Y$ variable. Do you think your $X$ variables will do a good job of predicting your $Y$ variable? Why or why not? What impact do you think this will have on your scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: I don't think that these X variable do a good job at predicting the y variables. On the surface the questions don't have anything to do with whether someone is lefthanded or righthanded. One could imagine that there might be something a little bit deeper that would emerge when you were running analysis but if you just look at the top 5 correlated variables with y as seen below have almost no relationship. Age is the highest correlation and it seems reasonable to assume that if a persons age is more correlate with lefthandedness than any of the questions asked, that there is essentially no predictive power.\n",
    "\n",
    "age\t0.030882\n",
    "Q26\t0.018077\n",
    "education\t0.017367\n",
    "Q25\t0.015104\n",
    "orientation\t0.014769\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Using accuracy as your metric, evaluate all eight of your models on both the training and testing sets. Put your scores below. (If you want to be fancy and generate a table in Markdown, there's a [Markdown table generator site linked here](https://www.tablesgenerator.com/markdown_tables#).)\n",
    "- Note: Your answers here might look a little weird. You didn't do anything wrong; that's to be expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this lesson was to teach you, in general, how hypothesis testing works. We showed you what is probably the most common variety of hypothesis test: the $t$-test. However, there are kajillions of other ones out there. It's not worth our time to go over so many more of them, as they all have the same implementation and interpretation, just in different situations. Instead, here is a list of many of the \"big\" ones and when to use them:\n",
    "\n",
    "| Model | Alphas | N-Neighbors | CV Score | Test Score |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| KNneighbors | N/A | 3  | 0.902 | 0.848\n",
    "| KNneighbors | N/A | 5  | 0.889 | 0.870\n",
    "| KNneighbors | N/A | 15  | 0.887 | 0.885\n",
    "| KNneighbors | N/A | 25  | 0.887 | 0.885\n",
    "| Logistic Reg l1 | 1 | N/A  | 0.887 | 0.885\n",
    "| Logistic Reg l1 | 10 | N/A  | 0.887 | 0.885\n",
    "| Logistic Reg l2 | 1 | N/A  | 0.887 | 0.885\n",
    "| Logistic Reg l2 | 10 | N/A  | 0.887 | 0.885\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. In which of your $k$-NN models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The KNN model where N-Neighbors = 3 there is evidence of overfitting. You can see that based on the difference between the train data score and the test data score. For the training set, the Cross Validation gives a score of 0.902 but on the test data set, it give you a score of 0.848. This is becuase having fewer N will tend toward overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Broadly speaking, how does the value of $k$ in $k$-NN affect the bias-variance tradeoff? (i.e. As $k$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: As you increase the the value of K in KNN you have less variance. So with smaller values of K the model is overfit and has much higher variance. We saw this in our results above. When K=3 the difference between the training score and the testing score was about 6%. However when K = 15 & 25 the difference between teh training score and the testing score was 0.2%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. If you have a $k$-NN model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: You can regularize, you can change the value of K, you can try using a different distance function while running KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. In which of your logistic regression models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: There isn't trong evidence of Overfitting in the models. The variance is relatively low as we can see by the similar scores we recive from the training and testing datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Broadly speaking, how does the value of $C$ in logistic regression affect the bias-variance tradeoff? (i.e. As $C$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: . Increasing the C parameter leads to higher rates of variance. Decreasing the C parameter leads to stronger regularization so this will decrease the variance and increase the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. For your logistic regression models, play around with the regularization hyperparameter, $C$. As you vary $C$, what happens to the fit and coefficients in the model? What do you think this means in the context of this specific problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: As I change the hyperparameter C the coefficients change very little. This means that changing the hyperparameters in the model doesnt' change how the model behaves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. If you have a logistic regression model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Change the value of C to be lower, scale your data, use fewer variables in your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "### 24. Suppose you want to understand which psychological features are most important in determining left-handedness. Would you rather use $k$-NN or logistic regression? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: I would use logistic regression because you can look at the coefficients of the different features and see how they predictedness lefthandedness. KNN is just looking at the closest values to make predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Select your logistic regression model that utilized LASSO regularization with $\\alpha = 1$. Interpret the coefficient for `Q1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00569758 -0.04638346 -0.01853951 -0.08578679  0.0611854   0.01498284\n",
      "   0.02313173 -0.15160932 -0.07244508  0.09335324  0.02060853 -0.02588533\n",
      "  -0.02263529  0.01699182  0.          0.02431994  0.02555358  0.02070302\n",
      "  -0.04698055 -0.04648088 -0.05736181 -0.10935238 -0.03332322  0.00988677\n",
      "   0.03288868  0.10455288  0.00971169  0.01825499  0.06540237  0.0542085\n",
      "   0.03288798 -0.03912474 -0.02451964 -0.02074129  0.02332908  0.\n",
      "  -0.03805837  0.08445194 -0.07508504 -0.05909796 -0.06913453 -0.04056245\n",
      "  -0.09535763]]\n"
     ]
    }
   ],
   "source": [
    "print(LogRegL1.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The coefficent for Q1 is -0.0056 which means that people who have studied how to win at gambling are SLIGHTLY less likely to be lefthanded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. If you have to select one model overall to be your *best* model, which model would you select? Why?\n",
    "- Usually in the \"real world,\" you'll fit many types of models but ultimately need to pick only one! (For example, a client may not understand what it means to have multiple models, or if you're using an algorithm to make a decision, it's probably pretty challenging to use two or more algorithms simultaneously.) It's not always an easy choice, but you'll have to make it soon enough. Pick a model and defend why you picked this model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:I would pick the baseline model, which would just be the mean of the dataset. For this example it would be 452 out 3994 or about 11.3 %. I would use this because the other models do a very poor job at predicting lefthandedness. This is not surprising as we talked about earlier, the questions from this sruvey have very little predictive power. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Circle back to the three specific and conclusively answerable questions you came up with in Q1. Answer one of these for the professor based on the model you selected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8634331876055038\n",
      "0.8784671814599955\n",
      "0.8871461056424401\n",
      "0.8871461056424401\n",
      "\n",
      "Knn 3: 0.8958263772954925\n",
      "0.889482470784641\n",
      "0.8871452420701169\n",
      "0.8871452420701169\n",
      "\n",
      "\n",
      "0.8558558558558559\n",
      "0.8718718718718719\n",
      "0.8858858858858859\n",
      "0.8858858858858859\n",
      "0.8858858858858859\n",
      "0.8858858858858859\n",
      "0.8858858858858859\n",
      "0.8858858858858859\n",
      "[[-0.05218497 -0.08923711 -0.02971047  0.01727901  0.0402436  -0.0407415\n",
      "   0.00718819]]\n"
     ]
    }
   ],
   "source": [
    "X=lefthand[['Q2', 'Q4', 'Q13', 'Q14', 'Q16', 'Q40', 'Q44']]\n",
    "y=lefthand['hand']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn15 = KNeighborsClassifier(n_neighbors=15)\n",
    "knn25 = KNeighborsClassifier(n_neighbors=25)\n",
    "print(cross_val_score(knn3, X_train, y_train, cv=5).mean())\n",
    "print(cross_val_score(knn5, X_train, y_train, cv=5).mean())\n",
    "print(cross_val_score(knn15, X_train, y_train, cv=5).mean())\n",
    "print(cross_val_score(knn25, X_train, y_train, cv=5).mean())\n",
    "print('')\n",
    "\n",
    "knn3.fit(X_train, y_train)\n",
    "knn5.fit(X_train, y_train)\n",
    "knn15.fit(X_train, y_train)\n",
    "knn25.fit(X_train, y_train)\n",
    "\n",
    "print(f'Knn 3: {knn3.score(X_train, y_train)}')\n",
    "print(knn5.score(X_train, y_train))\n",
    "print(knn15.score(X_train, y_train))\n",
    "print(knn25.score(X_train, y_train))\n",
    "print('\\n')\n",
    "print(knn3.score(X_test, y_test))\n",
    "print(knn5.score(X_test, y_test))\n",
    "print(knn15.score(X_test, y_test))\n",
    "print(knn25.score(X_test, y_test))\n",
    "\n",
    "\n",
    "LogRegL1 = LogisticRegression(penalty='l1', C=1, solver='liblinear')\n",
    "LogRegL2 = LogisticRegression(penalty='l2', C=1, solver='liblinear')\n",
    "LogRegL1_10 = LogisticRegression(penalty='l1', C=10, solver='liblinear')\n",
    "LogRegL2_10 = LogisticRegression(penalty='l2', C=10, solver='liblinear')\n",
    "\n",
    "LogRegL1.fit(X_train, y_train)\n",
    "LogRegL2.fit(X_train, y_train)\n",
    "LogRegL1_10.fit(X_train, y_train)\n",
    "LogRegL2_10.fit(X_train, y_train)\n",
    "\n",
    "print(LogRegL1.score(X_test, y_test))\n",
    "print(LogRegL2.score(X_test, y_test))\n",
    "print(LogRegL1_10.score(X_test, y_test))\n",
    "print(LogRegL2_10.score(X_test, y_test))\n",
    "\n",
    "print(LogRegL1.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: It's pretty hard to interpret these coefficients. I tested to see if lefthandedness is more common in artistic people. The coefficients suggest that there is essentially no predictive power between the questions that related to a person being more artistic and their lefthandedness. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS:\n",
    "Looking for more to do? Probably not - you're busy! But if you want to, consider exploring the following. (They could make for a blog post!)\n",
    "- Create a visual plot comparing training and test metrics for various values of $k$ and various regularization schemes in logistic regression.\n",
    "- Rather than just evaluating models based on accuracy, consider using sensitivity, specificity, etc.\n",
    "- In the context of predicting left-handedness, why are unbalanced classes concerning? If you were to re-do this process given those concerns, what changes might you make?\n",
    "- Fit and evaluate a generalized linear model other than logistic regression (e.g. Poisson regression).\n",
    "- Suppose this data were in a `SQL` database named `data` and a table named `inventory`. What `SQL` query would return the count of people who were right-handed, left-handed, both, or missing with their class labels of 1, 2, 3, and 0, respectively? (You can assume you've already logged into the database.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
